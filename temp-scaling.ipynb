{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "mpl.rcParams[\"font.family\"] = \"serif\"\n",
    "mpl.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.optimize import Bounds, minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False).fit([[0], [1]])\n",
    "\n",
    "def TS_probs(logits, temp):\n",
    "    logits_ts = logits  / temp\n",
    "    probs_ts = np.exp(logits_ts) / np.sum(np.exp(logits_ts), axis=1, keepdims=True)\n",
    "    \n",
    "    return probs_ts\n",
    "\n",
    "def f(x, *args):\n",
    "    probs = args[0]\n",
    "    labels = ohe.transform(args[1].reshape(-1, 1))\n",
    "    \n",
    "    probs_ets = TS_probs(probs, x)\n",
    "    nll = np.sum(labels * np.log(probs_ets), axis=1)\n",
    "    \n",
    "    return - np.mean(nll)\n",
    "\n",
    "my_bounds = Bounds(lb=np.array([0]), ub=np.array([np.inf]))\n",
    "x0 = np.float64([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run the `model-training.ipynb` notebook to generate predicted probability vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temperature Scaling of Individual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of training set sizes used for training the model:\n",
    "tr_sizes = [200, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "# Dataset versions:\n",
    "datasets = [1, 2, 3]\n",
    "\n",
    "for d_num in datasets:\n",
    "    p = pathlib.Path(f'results/BIC{d_num}/NN-TS/')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    labels_cal = np.loadtxt(f'data/BIC{d_num}/train_output_data.txt')[10000:11000]\n",
    "    labels_test = np.loadtxt(f'data/BIC{d_num}/test_output_data.txt')\n",
    "    \n",
    "    for tr_size in tr_sizes:\n",
    "        for model_num in range(10):\n",
    "            probs_cal = np.load(f'results/BIC{d_num}/NN/probs-cal-tr_size-{tr_size}-model_num-{model_num}.npy')\n",
    "            probs_test = np.load(f'results/BIC{d_num}/NN/probs-test-tr_size-{tr_size}-model_num-{model_num}.npy')\n",
    "            res = minimize(fun=f, x0=x0, args=(np.log(probs_cal).astype('float64'), labels_cal), method='SLSQP', bounds=my_bounds, tol=1e-15)\n",
    "            probs_test_ts = TS_probs(np.log(probs_test), res.x)\n",
    "            np.save(f'results/BIC{d_num}/NN-TS/probs-test-tr_size-{tr_size}-model_num-{model_num}.npy', probs_test_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temperature Scaling of Aggregated Probability Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of training set sizes used for training the model:\n",
    "tr_sizes = [200, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "# Dataset versions:\n",
    "datasets = [1, 2, 3]\n",
    "\n",
    "for d_num in datasets:\n",
    "    p = pathlib.Path(f'results/BIC{d_num}/NN-AGG-TS/')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    p = pathlib.Path(f'results/BIC{d_num}/NN-AGG/')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    labels_cal = np.loadtxt(f'data/BIC{d_num}/train_output_data.txt')[10000:11000]\n",
    "    labels_test = np.loadtxt(f'data/BIC{d_num}/test_output_data.txt')\n",
    "    \n",
    "    for tr_size in tr_sizes:\n",
    "        probs_cal_agg = np.zeros((len(labels_cal), 2))\n",
    "        probs_test_agg = np.zeros((len(labels_test), 2))\n",
    "        for model_num in range(10):\n",
    "            probs_cal_agg += np.load(f'results/BIC{d_num}/NN/probs-cal-tr_size-{tr_size}-model_num-{model_num}.npy') / 10\n",
    "            probs_test_agg += np.load(f'results/BIC{d_num}/NN/probs-test-tr_size-{tr_size}-model_num-{model_num}.npy') / 10\n",
    "        res = minimize(fun=f, x0=x0, args=(np.log(probs_cal_agg).astype('float64'), labels_cal), method='SLSQP', bounds=my_bounds, tol=1e-15)\n",
    "        probs_test_agg_ts = TS_probs(np.log(probs_test_agg), res.x)\n",
    "        np.save(f'results/BIC{d_num}/NN-AGG-TS/probs-test-tr_size-{tr_size}.npy', probs_test_agg_ts)\n",
    "        np.save(f'results/BIC{d_num}/NN-AGG/probs-test-tr_size-{tr_size}.npy', probs_test_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregating Individual Temperature Scaled Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of training set sizes used for training the model:\n",
    "tr_sizes = [200, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "# Dataset versions:\n",
    "datasets = [1, 2, 3]\n",
    "\n",
    "for d_num in datasets:\n",
    "    labels_test = np.loadtxt(f'data/BIC{d_num}/test_output_data.txt')\n",
    "    p = pathlib.Path(f'results/BIC{d_num}/NN-TS-AGG/')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    for tr_size in tr_sizes:\n",
    "        probs_test_ts_agg = np.zeros((len(labels_test), 2))\n",
    "        for model_num in range(10):\n",
    "            probs_test_ts_agg += np.load(f'results/BIC{d_num}/NN-TS/probs-test-tr_size-{tr_size}-model_num-{model_num}.npy')\n",
    "        np.save(f'results/BIC{d_num}/NN-TS-AGG/probs-test-tr_size-{tr_size}.npy', probs_test_ts_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temperature Scaling of Individual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset versions:\n",
    "datasets = [1, 2, 3]\n",
    "\n",
    "for d_num in datasets:\n",
    "    p = pathlib.Path(f'results/ABC{d_num}/NN-TS/')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    labels_cal = np.load(f'data/ABC{d_num}/labels_val.npy')[:1000]\n",
    "    labels_test = np.load(f'data/ABC{d_num}/labels_test.npy')\n",
    "    \n",
    "    for model_num in range(10):\n",
    "        probs_cal = np.load(f'results/ABC{d_num}/NN/probs-cal-model_num-{model_num}.npy')\n",
    "        probs_test = np.load(f'results/ABC{d_num}/NN/probs-test-model_num-{model_num}.npy')\n",
    "        res = minimize(fun=f, x0=x0, args=(np.log(probs_cal).astype('float64'), labels_cal), method='SLSQP', bounds=my_bounds, tol=1e-15)\n",
    "        probs_test_ts = TS_probs(np.log(probs_test), res.x)\n",
    "        np.save(f'results/ABC{d_num}/NN-TS/probs-test-model_num-{model_num}.npy', probs_test_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temperature Scaling of Aggregated Probability Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset versions:\n",
    "datasets = [1, 2, 3]\n",
    "\n",
    "for d_num in datasets:\n",
    "    p = pathlib.Path(f'results/ABC{d_num}/NN-AGG-TS/')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    p = pathlib.Path(f'results/ABC{d_num}/NN-AGG/')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    labels_cal = np.load(f'data/ABC{d_num}/labels_val.npy')[:1000]\n",
    "    labels_test = np.load(f'data/ABC{d_num}/labels_test.npy')\n",
    "    \n",
    "    probs_cal_agg = np.zeros((len(labels_cal), 2))\n",
    "    probs_test_agg = np.zeros((len(labels_test), 2))\n",
    "    for model_num in range(10):\n",
    "        probs_cal_agg += np.load(f'results/ABC{d_num}/NN/probs-cal-model_num-{model_num}.npy') / 10\n",
    "        probs_test_agg += np.load(f'results/ABC{d_num}/NN/probs-test-model_num-{model_num}.npy') / 10\n",
    "    res = minimize(fun=f, x0=x0, args=(np.log(probs_cal_agg).astype('float64'), labels_cal), method='SLSQP', bounds=my_bounds, tol=1e-15)\n",
    "    probs_test_agg_ts = TS_probs(np.log(probs_test_agg), res.x)\n",
    "    np.save(f'results/ABC{d_num}/NN-AGG-TS/probs-test.npy', probs_test_agg_ts)\n",
    "    np.save(f'results/ABC{d_num}/NN-AGG/probs-test.npy', probs_test_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregating Individual Temperature Scaled Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset versions:\n",
    "datasets = [1, 2, 3]\n",
    "\n",
    "for d_num in datasets:\n",
    "    p = pathlib.Path(f'results/ABC{d_num}/NN-TS-AGG/')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    labels_test = np.load(f'data/ABC{d_num}/labels_test.npy')\n",
    "    probs_test_ts_agg = np.zeros((len(labels_test), 2))\n",
    "    for model_num in range(10):\n",
    "        probs_test_ts_agg += np.load(f'results/ABC{d_num}/NN-TS/probs-test-model_num-{model_num}.npy') / 10\n",
    "    np.save(f'results/ABC{d_num}/NN-TS-AGG/probs-test.npy', probs_test_ts_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crack Path Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temperature Scaling of Individual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pathlib.Path(f'results/Crack-Path/NN-TS/')\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "labels_cal = np.load(f'data/Crack-Path/dmg-train.npy')[20000:21000].reshape(-1)\n",
    "labels_test = np.load(f'data/Crack-Path/dmg-test.npy').reshape(-1)\n",
    "    \n",
    "for model_num in range(10):\n",
    "    probs_cal = np.load(f'results/Crack-Path/NN/probs-cal-model_num-{model_num}.npy')\n",
    "    probs_test = np.load(f'results/Crack-Path/NN/probs-test-model_num-{model_num}.npy')\n",
    "    res = minimize(fun=f, x0=x0, args=(np.log(probs_cal).astype('float64'), labels_cal), method='SLSQP', bounds=my_bounds, tol=1e-15)\n",
    "    probs_test_ts = TS_probs(np.log(probs_test), res.x)\n",
    "    np.save(f'results/Crack-Path/NN-TS/probs-test-model_num-{model_num}.npy', probs_test_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temperature Scaling of Aggregated Probability Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pathlib.Path(f'results/Crack-Path/NN-AGG-TS/')\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "p = pathlib.Path(f'results/Crack-Path/NN-AGG/')\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "labels_cal = np.load(f'data/Crack-Path/dmg-train.npy')[20000:21000].reshape(-1)\n",
    "labels_test = np.load(f'data/Crack-Path/dmg-test.npy').reshape(-1)\n",
    "\n",
    "probs_cal_agg = np.zeros((len(labels_cal), 2))\n",
    "probs_test_agg = np.zeros((len(labels_test), 2))\n",
    "for model_num in range(10):\n",
    "    probs_cal_agg += np.load(f'results/Crack-Path/NN/probs-cal-model_num-{model_num}.npy') / 10\n",
    "    probs_test_agg += np.load(f'results/Crack-Path/NN/probs-test-model_num-{model_num}.npy') / 10\n",
    "res = minimize(fun=f, x0=x0, args=(np.log(probs_cal_agg).astype('float64'), labels_cal), method='SLSQP', bounds=my_bounds, tol=1e-15)\n",
    "probs_test_agg_ts = TS_probs(np.log(probs_test_agg), res.x)\n",
    "np.save(f'results/Crack-Path/NN-AGG-TS/probs-test.npy', probs_test_agg_ts)\n",
    "np.save(f'results/Crack-Path/NN-AGG/probs-test.npy', probs_test_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregating Individual Temperature Scaled Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = np.load(f'data/Crack-Path/dmg-test.npy').reshape(-1)\n",
    "p = pathlib.Path(f'results/Crack-Path/NN-TS-AGG/')\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "probs_test_ts_agg = np.zeros((len(labels_test), 2))\n",
    "for model_num in range(10):\n",
    "    probs_test_ts_agg += np.load(f'results/Crack-Path/NN-TS/probs-test-model_num-{model_num}.npy')\n",
    "np.save(f'results/Crack-Path/NN-TS-AGG/probs-test.npy', probs_test_ts_agg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
